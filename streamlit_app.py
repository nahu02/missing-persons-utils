import logging
import asyncio
import streamlit as st
from datetime import datetime, timedelta
import io
import pandas as pd

from collect_missing import scrape_missing_persons

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("missing-persons.log"), logging.StreamHandler()],
)

# Page configuration
st.set_page_config(
    page_title="Elt≈±nt Szem√©lyek",
    page_icon="üîç",
    layout="wide",
)

# Create tabs for navigation
tab1, tab2 = st.tabs(["Keres√©s", "√ñsszehasonl√≠t√°s"])

# TAB 1: SEARCH PAGE
with tab1:
    # Main title for the app
    st.title("üîç Elt≈±nt Szem√©ly Keres≈ë")

    st.write("""
        Ez az alkalmaz√°s a [Rend≈ërs√©g weboldal√°r√≥l](https://www.police.hu/hu/koral/eltunt-szemelyek) gy≈±jt adatokat az elt≈±nt szem√©lyekr≈ël
        √©s r√©szletes inform√°ci√≥kat jelen√≠t meg r√≥luk.
    """)

    # Calculate default min birth date (12 years ago from today)
    default_min_birth_date = (datetime.now() - timedelta(days=365.25 * 12)).strftime(
        "%Y-%m-%d"
    )

    # Search filters section
    st.header("Keres√©si Felt√©telek")

    st.info(
        "Add meg a keres√©si felt√©teleket, majd kattints az 'Elt≈±nt Szem√©lyek Keres√©se' gombra!"
    )

    # Create a two-column layout for the name and birth place fields
    col1, col2 = st.columns(2)

    with col1:
        name = st.text_input(
            "N√©v", value="", help="Sz≈±r√©s n√©v alapj√°n", key="search_name"
        )

    with col2:
        birth_place = st.text_input(
            "Sz√ºlet√©si Hely",
            value="",
            help="Sz≈±r√©s sz√ºlet√©si hely alapj√°n",
            key="search_birthplace",
        )

    # Create a layout for birth date filters
    col1, col2 = st.columns(2)

    with col1:
        birth_date_min = st.date_input(
            "Sz√ºlet√©si D√°tum (minimum)",
            datetime.strptime(default_min_birth_date, "%Y-%m-%d"),
            help="Sz≈±r√©s minimum sz√ºlet√©si d√°tum alapj√°n (alap√©rtelmezett: 12 √©ve)",
            key="search_min_date",
        )

    with col2:
        use_max_date = st.checkbox(
            "Sz√ºlet√©si D√°tum (maximum) be√°ll√≠t√°sa", value=False, key="use_max_date"
        )
        birth_date_max = None
        if use_max_date:
            birth_date_max = st.date_input(
                "Sz√ºlet√©si D√°tum (maximum)",
                datetime.now(),
                help="Sz≈±r√©s maximum sz√ºlet√©si d√°tum alapj√°n",
                key="search_max_date",
            )

    # Search button across the full width
    search_button = st.button(
        "Elt≈±nt Szem√©lyek Keres√©se",
        type="primary",
        use_container_width=True,
        key="search_button",
    )

    # Main content area for search
    if search_button:
        # Convert dates to string format for API
        min_birth_date_str = birth_date_min.strftime("%Y-%m-%d")
        max_birth_date_str = birth_date_max.strftime("%Y-%m-%d") if use_max_date else ""

        progress_placeholder = st.empty()

        with st.spinner(
            "Adatok lek√©rdez√©se a Rend≈ërs√©g weboldal√°r√≥l. Ez eltarthat egy ideig..."
        ):
            try:
                # Create a progress display
                progress_container = progress_placeholder.container()
                progress_container.text("Keres√©s ind√≠t√°sa...")

                # Execute the async function
                df = asyncio.run(
                    scrape_missing_persons(
                        name=name,
                        birth_place=birth_place,
                        birth_date_min=min_birth_date_str,
                        birth_date_max=max_birth_date_str,
                    )
                )

                # Clear progress display when done
                progress_placeholder.empty()

                if df.empty:
                    st.warning("Nem tal√°lhat√≥ eredm√©ny a megadott felt√©telekkel.")
                else:
                    st.success(
                        f"A keres√©si felt√©telek alapj√°n tal√°ltam {len(df)} elt≈±nt szem√©lyt."
                    )

                    # Display data
                    st.subheader("Eredm√©nyek")

                    st.dataframe(df, use_container_width=True, hide_index=True)

                    # Add download button
                    # Create a BytesIO buffer for Excel file
                    buffer = io.BytesIO()
                    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                        df.to_excel(writer, index=False)
                    buffer.seek(0)

                    st.download_button(
                        "Let√∂lt√©s Excel f√°jlk√©nt",
                        buffer,
                        f"eltunt-szemelyek_{datetime.now().strftime('%Y-%m-%d')}_min-szuletes-{min_birth_date_str}.xlsx",
                        "application/vnd.ms-excel",
                        key="download-excel",
                        icon="‚¨áÔ∏è",
                    )

            except Exception as e:
                st.error(f"Hiba a keres√©s sor√°n: {e}")
                logging.error(f"Error in Streamlit app: {e}")

# TAB 2: COMPARISON PAGE
with tab2:
    st.title("üîÑ Elt≈±nt Szem√©lyek Adatb√°zis √ñsszehasonl√≠t√°s √©s Egyes√≠t√©s")
    st.write("""
        Ez a funkci√≥ lehet≈ëv√© teszi egy megl√©v≈ë √∂sszehasonl√≠t√°si adatb√°zis √©s √∫j adatok egyes√≠t√©s√©t:
        1. Az √∫j szem√©lyek hozz√°ad√°sra ker√ºlnek a megl√©v≈ë adatb√°zishoz
        2. A mai d√°tummal egy √∫j oszlop is l√©trej√∂n az aktu√°lis elt≈±n√©si d√°tummal
        Ez seg√≠t nyomon k√∂vetni, hogy ki mikor t≈±nt el, kit tal√°ltak meg, √©s ki az, aki esetleg √∫jra elt≈±nt.
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Megl√©v≈ë √∂sszehasonl√≠t√°si adatb√°zis")
        st.write(
            "Ez a folyamatosan friss√≠tett adatb√°zisod, amely az elt≈±nt szem√©lyek el≈ëzm√©nyeit tartalmazza. "
            + "Ha m√©g nincs ilyen adatb√°zisod, t√∂ltsd fel az els≈ë f√°jlt."
        )
        ongoing_file = st.file_uploader(
            "V√°laszd ki a megl√©v≈ë adatb√°zis Excel f√°jlt",
            type=["xlsx", "xls"],
            key="ongoing_file",
        )

    with col2:
        st.subheader("√öj adatok")
        st.write(
            "Ez a legfrissebb elt≈±nt szem√©lyek list√°ja, amelyet hozz√° szeretn√©l adni az √∂sszehasonl√≠t√°si adatb√°zishoz."
        )
        new_file = st.file_uploader(
            "V√°laszd ki az √∫j adatokat tartalmaz√≥ Excel f√°jlt",
            type=["xlsx", "xls"],
            key="new_file",
        )

    compare_button = st.button(
        "Adatok egyes√≠t√©se", type="primary", use_container_width=True
    )

    if compare_button:
        logging.info("Merging data...")
        if not ongoing_file or not new_file:
            st.error("K√©rlek t√∂lts fel mindk√©t Excel f√°jlt az egyes√≠t√©shez!")
            logging.error("Missing one or both files for merging.")
        else:
            try:
                with st.spinner("Adatok egyes√≠t√©se folyamatban..."):
                    # Read Excel files
                    ongoing_df = pd.read_excel(ongoing_file)
                    new_df = pd.read_excel(new_file)

                    # Get file names for reference
                    ongoing_file_name = ongoing_file.name
                    new_file_name = new_file.name

                    # Check if the dataframes have any content
                    if ongoing_df.empty or new_df.empty:
                        st.warning("Az egyik vagy mindk√©t f√°jl √ºres!")
                    else:
                        st.success(
                            f"Sikeres beolvas√°s! A megl√©v≈ë adatb√°zis {len(ongoing_df)} sort, az √∫j adatok {len(new_df)} sort tartalmaznak."
                        )

                        # Find a column in the new data that matches "Elt≈±n√©s d√°tuma XXX" pattern
                        date_columns = [
                            col for col in new_df.columns if "Elt≈±n√©s d√°tuma" in col
                        ]

                        if date_columns:
                            # Use the found "Elt≈±n√©s d√°tuma XXX" column
                            eltunes_column_name = date_columns[0]
                            missing_date_source_column = date_columns[0]
                            logging.debug(
                                f"A k√∂vetkez≈ë oszlop haszn√°lata: '{eltunes_column_name}'"
                            )
                        elif "Elt≈±n√©s d√°tuma" in new_df.columns:
                            # Fall back to default if no "Elt≈±n√©s d√°tuma XXX" exists but "Elt≈±n√©s d√°tuma" does
                            current_date = datetime.now().strftime("%Y-%m-%d")
                            eltunes_column_name = f"Elt≈±n√©s d√°tuma {current_date}"
                            missing_date_source_column = "Elt≈±n√©s d√°tuma"
                            logging.debug(
                                f"Nincs 'Elt≈±n√©s d√°tuma XXX' oszlop az √∫j adatokban, '{missing_date_source_column}' oszlop haszn√°lata √©s √∫j '{eltunes_column_name}' oszlop l√©trehoz√°sa."
                            )
                        else:
                            st.error(
                                "Az √∫j adatokban nem tal√°lhat√≥ 'Elt≈±n√©s d√°tuma' oszlop!"
                            )
                            st.stop()

                        # Check for required columns in new data
                        required_columns = [
                            "N√©v",
                            "Sz√ºlet√©si d√°tum",
                            missing_date_source_column,
                        ]
                        if not all(col in new_df.columns for col in required_columns):
                            missing_cols = [
                                col
                                for col in required_columns
                                if col not in new_df.columns
                            ]
                            st.error(
                                f"Az √∫j adatokb√≥l hi√°nyoznak k√∂telez≈ë oszlopok: {', '.join(missing_cols)}"
                            )
                            st.stop()

                        # Display basic info about uploaded files
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write(f"**{ongoing_file_name}** oszlopai:")
                            st.write(", ".join(ongoing_df.columns.tolist()))
                        with col2:
                            st.write(f"**{new_file_name}** oszlopai:")
                            st.write(", ".join(new_df.columns.tolist()))

                        # Create a backup of original ongoing data
                        original_ongoing_df = ongoing_df.copy()

                        # Define person identifier columns
                        id_columns = ["N√©v", "Sz√ºlet√©si d√°tum"]

                        # Ensure all required columns exist in ongoing data
                        required_base_columns = [
                            "N√©v",
                            "Nem",
                            "Sz√ºlet√©si hely",
                            "Sz√ºlet√©si d√°tum",
                            "Sz√ºlet√©si orsz√°g",
                        ]
                        for col in required_base_columns:
                            if col not in ongoing_df.columns:
                                if col in new_df.columns:
                                    ongoing_df[col] = None
                                else:
                                    ongoing_df[col] = None
                                    st.warning(
                                        f"A '{col}' oszlop hi√°nyzik mindk√©t f√°jlb√≥l. √úres oszlop besz√∫rva."
                                    )

                        # Add the new column for current missing date to ongoing data if it doesn't exist already
                        if eltunes_column_name not in ongoing_df.columns:
                            ongoing_df[eltunes_column_name] = None

                        # Find people who exist in both datasets
                        common_people = pd.merge(
                            ongoing_df[id_columns],
                            new_df[id_columns],
                            on=id_columns,
                            how="inner",
                        )

                        # Update existing records with new missing date
                        for _, row in common_people.iterrows():
                            # Create mask to find the person in both dataframes
                            ongoing_mask = (ongoing_df["N√©v"] == row["N√©v"]) & (
                                ongoing_df["Sz√ºlet√©si d√°tum"] == row["Sz√ºlet√©si d√°tum"]
                            )
                            new_mask = (new_df["N√©v"] == row["N√©v"]) & (
                                new_df["Sz√ºlet√©si d√°tum"] == row["Sz√ºlet√©si d√°tum"]
                            )

                            # Get the missing date from new data
                            missing_date = new_df.loc[
                                new_mask, missing_date_source_column
                            ].values[0]

                            # Update the current missing date in ongoing data
                            ongoing_df.loc[ongoing_mask, eltunes_column_name] = (
                                missing_date
                            )

                        # Find people who are only in the new data
                        new_only_people = pd.merge(
                            new_df[id_columns],
                            ongoing_df[id_columns],
                            on=id_columns,
                            how="left",
                            indicator=True,
                        )
                        new_only_people = new_only_people[
                            new_only_people["_merge"] == "left_only"
                        ].drop(columns=["_merge"])

                        # Create new records for people only in new data
                        if len(new_only_people) > 0:
                            # Get all records from new data that are new people
                            new_records = pd.merge(
                                new_df, new_only_people, on=id_columns
                            )

                            # Ensure new records have all the columns from ongoing data
                            for col in ongoing_df.columns:
                                if (
                                    col not in new_records.columns
                                    and col != eltunes_column_name
                                ):
                                    new_records[col] = None

                            # Set the current missing date
                            new_records[eltunes_column_name] = new_records[
                                missing_date_source_column
                            ]

                            # Select only the columns that are in ongoing_df
                            new_records = new_records[ongoing_df.columns]

                            # Append new records to ongoing data
                            ongoing_df = pd.concat(
                                [ongoing_df, new_records], ignore_index=True
                            )

                        # Display results
                        st.subheader("Adatb√°zis egyes√≠t√©s eredm√©nye")

                        num_common = len(common_people)
                        num_new = len(new_only_people)
                        num_only_in_ongoing = len(ongoing_df) - num_common - num_new

                        # Create a download button for the updated database
                        buffer = io.BytesIO()

                        with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                            ongoing_df.to_excel(
                                writer, sheet_name="Adatb√°zis", index=False
                            )

                            # Add a summary sheet
                            summary_data = {
                                "Le√≠r√°s": [
                                    "Megl√©v≈ë adatb√°zis",
                                    "√öj adatok",
                                    "Friss√≠t√©s d√°tuma",
                                    "Haszn√°lt elt≈±n√©si d√°tum oszlop",
                                    "Megl√©v≈ë adatb√°zis rekordok sz√°ma",
                                    "√öj adatok sz√°ma",
                                    "Friss√≠tett adatok (tov√°bbra is keresettek, vagy √∫jra elt≈±ntek) sz√°ma",
                                    "Hozz√°adott √∫j rekordok (√∫jonnan, ez el≈ëtt m√©g sosem elt≈±ntek) sz√°ma",
                                    "Csak megl√©v≈ëben tal√°lhat√≥ rekordok (m√°r nem keresettek) sz√°ma",
                                    "Egyes√≠tett adatb√°zis rekordok sz√°ma",
                                ],
                                "√ârt√©k": [
                                    ongoing_file_name,
                                    new_file_name,
                                    datetime.now().strftime("%Y-%m-%d"),
                                    eltunes_column_name,
                                    len(original_ongoing_df),
                                    len(new_df),
                                    num_common,
                                    num_new,
                                    num_only_in_ongoing,
                                    len(ongoing_df),
                                ],
                            }
                            pd.DataFrame(summary_data).to_excel(
                                writer,
                                sheet_name=f"√ñsszes√≠t√©s {datetime.now().strftime('%Y-%m-%d')}",
                                index=False,
                            )

                            # Copy all other sheets from the ongoing file (if any)
                            try:
                                ongoing_excel = pd.ExcelFile(
                                    ongoing_file, engine="openpyxl"
                                )
                                # Check if there are more than 1 sheets
                                if len(ongoing_excel.sheet_names) > 1:
                                    for sheet_name in ongoing_excel.sheet_names:
                                        # Skip the first sheet as we already created the main data sheet
                                        if sheet_name != ongoing_excel.sheet_names[0]:
                                            # Read the sheet and write it to the new file
                                            sheet_df = pd.read_excel(
                                                ongoing_file, sheet_name=sheet_name
                                            )
                                            sheet_df.to_excel(
                                                writer,
                                                sheet_name=sheet_name,
                                                index=False,
                                            )
                            except Exception as e:
                                logging.warning(
                                    f"Could not copy additional sheets from ongoing file: {e}"
                                )

                        buffer.seek(0)

                        # Show tabs with results
                        tab1, tab2, tab3, tab4 = st.tabs(
                            [
                                "√ñsszes√≠tett adatok",
                                f"Friss√≠tett rekordok ({num_common})",
                                f"√öj rekordok ({num_new})",
                                f"Csak megl√©v≈ëben ({num_only_in_ongoing})",
                            ]
                        )

                        with tab1:
                            st.write("Az √∫j egyes√≠tett adatb√°zis:")
                            st.dataframe(
                                ongoing_df, use_container_width=True, hide_index=True
                            )

                            st.download_button(
                                "Friss√≠tett adatb√°zis let√∂lt√©se Excel form√°tumban",
                                buffer,
                                f"eltunt_szemelyek_adatbazis_{datetime.now().strftime('%Y-%m-%d')}.xlsx",
                                "application/vnd.ms-excel",
                                key="database-download",
                                icon="‚¨áÔ∏è",
                            )

                        with tab2:
                            if num_common == 0:
                                st.info(
                                    "Nincs olyan szem√©ly, aki mindk√©t adatb√°zisban szerepel."
                                )
                            else:
                                st.write(
                                    f"Az al√°bbi {num_common} szem√©ly mindk√©t adatb√°zisban szerepel, az elt≈±n√©si d√°tumuk friss√≠tve lett. "
                                    + "K√©ken kiemelve azok a rekordok, ahol az elt≈±n√©si d√°tum v√°ltozott (ha van ilyen):"
                                )
                                common_records = pd.merge(
                                    ongoing_df, common_people, on=id_columns
                                )

                                # Find all date columns that contain "Elt≈±n√©s d√°tuma"
                                date_columns = [
                                    col
                                    for col in common_records.columns
                                    if "Elt≈±n√©s d√°tuma" in col
                                ]

                                if len(date_columns) >= 2:
                                    # Sort date columns by date (newest first)
                                    date_columns.sort(reverse=True)

                                    # Get current and previous date columns
                                    current_date_col = date_columns[0]  # newest
                                    previous_date_col = date_columns[1]  # second newest

                                    # Create a style function to highlight rows with different dates
                                    def highlight_changed_dates(row):
                                        if pd.notna(row[current_date_col]) and pd.notna(
                                            row[previous_date_col]
                                        ):
                                            if (
                                                row[current_date_col]
                                                != row[previous_date_col]
                                            ):
                                                return [
                                                    "background-color: CornflowerBlue"
                                                ] * len(row)
                                        return [""] * len(row)

                                    # Apply styling
                                    styled_df = common_records.style.apply(
                                        highlight_changed_dates, axis=1
                                    )
                                    st.dataframe(
                                        styled_df,
                                        use_container_width=True,
                                        hide_index=True,
                                    )
                                else:
                                    # Not enough date columns for comparison
                                    st.dataframe(
                                        common_records,
                                        use_container_width=True,
                                        hide_index=True,
                                    )

                        with tab3:
                            if num_new == 0:
                                st.info(
                                    "Nincs olyan szem√©ly, aki csak az √∫j adatokban szerepel."
                                )
                            else:
                                st.write(
                                    f"Az al√°bbi {num_new} √∫j szem√©ly hozz√°ad√°sra ker√ºlt az adatb√°zishoz (√∫jonnan elt≈±ntek):"
                                )
                                new_records_display = pd.merge(
                                    ongoing_df, new_only_people, on=id_columns
                                )
                                st.dataframe(
                                    new_records_display,
                                    use_container_width=True,
                                    hide_index=True,
                                )

                        with tab4:
                            only_in_ongoing_mask = ~ongoing_df["N√©v"].isin(
                                common_people["N√©v"]
                            ) & ~ongoing_df["N√©v"].isin(new_only_people["N√©v"])
                            only_in_ongoing = ongoing_df[only_in_ongoing_mask]

                            if len(only_in_ongoing) == 0:
                                st.info(
                                    "Nincs olyan szem√©ly, aki csak a megl√©v≈ë adatb√°zisban szerepel."
                                )
                            else:
                                st.write(
                                    f"Az al√°bbi {len(only_in_ongoing)} szem√©ly csak a megl√©v≈ë adatb√°zisban szerepel (m√°r nem keresik ≈ëket):"
                                )
                                st.dataframe(
                                    only_in_ongoing,
                                    use_container_width=True,
                                    hide_index=True,
                                )

            except Exception as e:
                st.error(f"Hiba az adatok egyes√≠t√©se sor√°n: {str(e)}")
                logging.error(f"Error in merger feature: {e}")
                # Add detailed traceback for debugging
                import traceback

                logging.error(traceback.format_exc())
    else:
        st.info(
            "T√∂ltsd fel a megl√©v≈ë adatb√°zist √©s az √∫j adatokat tartalmaz√≥ Excel f√°jlokat, majd kattints az 'Adatok egyes√≠t√©se' gombra!"
        )
